{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d15b2f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in the dataset: 541909\n",
      "Number of records from the UK: 495478\n",
      "\n",
      "Original class distribution (UK data):\n",
      "1    3904\n",
      "0       8\n",
      "Name: Purchase, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1846: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])  # type: ignore[arg-type]\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:364: RuntimeWarning: divide by zero encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:364: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1846: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])  # type: ignore[arg-type]\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1846: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])  # type: ignore[arg-type]\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1846: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])  # type: ignore[arg-type]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=8, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=8, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=8, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Evaluation:\n",
      "Accuracy: 0.9676\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      1.00      0.10         2\n",
      "           1       1.00      0.97      0.98      1172\n",
      "\n",
      "    accuracy                           0.97      1174\n",
      "   macro avg       0.53      0.98      0.54      1174\n",
      "weighted avg       1.00      0.97      0.98      1174\n",
      "\n",
      "\n",
      "Random Forest Evaluation:\n",
      "Accuracy: 0.9983\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         2\n",
      "           1       1.00      1.00      1.00      1172\n",
      "\n",
      "    accuracy                           1.00      1174\n",
      "   macro avg       0.75      1.00      0.83      1174\n",
      "weighted avg       1.00      1.00      1.00      1174\n",
      "\n",
      "\n",
      "Logistic Regression Prediction:\n",
      "\n",
      "Logistic Regression: Actual vs Predicted (First 10 Rows):\n",
      "      Actual  Predicted\n",
      "2231       1          1\n",
      "3431       1          1\n",
      "574        1          1\n",
      "136        1          1\n",
      "3471       1          1\n",
      "2096       1          1\n",
      "133        1          1\n",
      "1418       1          1\n",
      "3384       1          1\n",
      "3418       1          1\n",
      "\n",
      "Random Forest Prediction\n",
      "\n",
      "Random Forest: Actual vs Predicted (First 10 Rows):\n",
      "      Actual  Predicted\n",
      "2231       1          1\n",
      "3431       1          1\n",
      "574        1          1\n",
      "136        1          1\n",
      "3471       1          1\n",
      "2096       1          1\n",
      "133        1          1\n",
      "1418       1          1\n",
      "3384       1          1\n",
      "3418       1          1\n"
     ]
    }
   ],
   "source": [
    "###classification without balancing dataset(UK)\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "file_path = r\"C:\\Users\\imran\\Downloads\\data.csv\"  # Update the file path\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Step 2: Filter Data for UK Customers\n",
    "data_uk = data[data['Country'] == 'United Kingdom']\n",
    "print(f\"Total records in the dataset: {data.shape[0]}\")\n",
    "print(f\"Number of records from the UK: {data_uk.shape[0]}\")\n",
    "\n",
    "# Step 3: Data Cleaning and Feature Engineering\n",
    "data_cleaned = data_uk.dropna(subset=['CustomerID']).copy()\n",
    "data_cleaned['InvoiceDate'] = pd.to_datetime(data_cleaned['InvoiceDate'])\n",
    "data_cleaned['TotalAmount'] = data_cleaned['Quantity'] * data_cleaned['UnitPrice']\n",
    "data_cleaned['Recency'] = (data_cleaned['InvoiceDate'].max() - data_cleaned['InvoiceDate']).dt.days\n",
    "\n",
    "# Aggregate features at the customer level\n",
    "customer_features = data_cleaned.groupby('CustomerID').agg(\n",
    "    TotalAmount=('TotalAmount', 'sum'),\n",
    "    TotalQuantity=('Quantity', 'sum'),\n",
    "    AvgUnitPrice=('UnitPrice', 'mean'),\n",
    "    Recency=('Recency', 'min'),\n",
    "    Frequency=('InvoiceNo', 'nunique'),\n",
    "    Purchase=('TotalAmount', lambda x: 1 if x.sum() > 0 else 0)  # Define target: Purchase (1/0)\n",
    ").reset_index()\n",
    "\n",
    "# Replace zeros or negative values in TotalQuantity and TotalAmount\n",
    "customer_features['TotalQuantity'] = customer_features['TotalQuantity'].replace(0, 1e-6)\n",
    "customer_features['TotalAmount'] = customer_features['TotalAmount'].replace(0, 1e-6)\n",
    "\n",
    "# Log-transform skewed features to reduce outliers\n",
    "customer_features['Log_TotalQuantity'] = np.log1p(customer_features['TotalQuantity'])\n",
    "customer_features['Log_TotalAmount'] = np.log1p(customer_features['TotalAmount'])\n",
    "\n",
    "# Replace infinite and NaN values\n",
    "customer_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "customer_features.dropna(inplace=True)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = ['TotalQuantity', 'AvgUnitPrice', 'Recency', 'Frequency', 'Log_TotalQuantity']\n",
    "customer_features[numeric_columns] = scaler.fit_transform(customer_features[numeric_columns])\n",
    "\n",
    "# Step 4: Define Features (X) and Target (y)\n",
    "X = customer_features.drop(columns=['CustomerID', 'Purchase', 'TotalAmount', 'Log_TotalAmount'])\n",
    "y = customer_features['Purchase']\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nOriginal class distribution (UK data):\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Step 5: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Step 6: Train Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42, class_weight='balanced')  # Using class weights to handle imbalance\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Train Random Forest\n",
    "rf_clf = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100, max_depth=8)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Evaluate Logistic Regression on Original Test Set\n",
    "print(\"\\nLogistic Regression Evaluation:\")\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log_reg):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "\n",
    "\n",
    "\n",
    "# Step 9: Evaluate Random Forest on Original Test Set\n",
    "print(\"\\nRandom Forest Evaluation:\")\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Display first 10 rows of actual vs predicted\n",
    "print(\"\\nLogistic Regression Prediction:\")\n",
    "log_reg_results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_log_reg})\n",
    "print(\"\\nLogistic Regression: Actual vs Predicted (First 10 Rows):\")\n",
    "print(log_reg_results.head(10))\n",
    "\n",
    "# Display first 10 rows of actual vs predicted\n",
    "print(\"\\nRandom Forest Prediction\")\n",
    "rf_results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_rf})\n",
    "print(\"\\nRandom Forest: Actual vs Predicted (First 10 Rows):\")\n",
    "print(rf_results.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eb68cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Overview:\n",
      "Number of rows: 541909\n",
      "Number of columns: 8\n",
      "\n",
      "Columns in the Dataset:\n",
      "['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']\n",
      "\n",
      "First 10 Rows of the Dataset:\n",
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "5    536365     22752         SET 7 BABUSHKA NESTING BOXES         2   \n",
      "6    536365     21730    GLASS STAR FROSTED T-LIGHT HOLDER         6   \n",
      "7    536366     22633               HAND WARMER UNION JACK         6   \n",
      "8    536366     22632            HAND WARMER RED POLKA DOT         6   \n",
      "9    536367     84879        ASSORTED COLOUR BIRD ORNAMENT        32   \n",
      "\n",
      "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
      "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
      "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "5  12/1/2010 8:26       7.65     17850.0  United Kingdom  \n",
      "6  12/1/2010 8:26       4.25     17850.0  United Kingdom  \n",
      "7  12/1/2010 8:28       1.85     17850.0  United Kingdom  \n",
      "8  12/1/2010 8:28       1.85     17850.0  United Kingdom  \n",
      "9  12/1/2010 8:34       1.69     13047.0  United Kingdom  \n",
      "\n",
      "Missing Values in Each Column:\n",
      "InvoiceNo           0\n",
      "StockCode           0\n",
      "Description      1454\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice           0\n",
      "CustomerID     135080\n",
      "Country             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Dataset\n",
    "file_path = r\"C:\\Users\\imran\\Downloads\\data.csv\"  # Update the file path if necessary\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Step 2: Display Dataset Information\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(f\"Number of rows: {data.shape[0]}\")\n",
    "print(f\"Number of columns: {data.shape[1]}\")\n",
    "\n",
    "# Step 3: Display Columns\n",
    "print(\"\\nColumns in the Dataset:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Step 4: View First 10 Rows\n",
    "print(\"\\nFirst 10 Rows of the Dataset:\")\n",
    "print(data.head(10))\n",
    "\n",
    "# Step 5: Check for Missing Values\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f0b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:364: RuntimeWarning: divide by zero encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:364: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK dataset class distribution:\n",
      "1    3904\n",
      "0       8\n",
      "Name: Purchase, dtype: int64\n",
      "\n",
      "Training set class distribution after SMOTE:\n",
      "1    2732\n",
      "0    2732\n",
      "Name: Purchase, dtype: int64\n",
      "\n",
      "Testing set class distribution after SMOTE:\n",
      "1    1172\n",
      "0    1172\n",
      "Name: Purchase, dtype: int64\n",
      "\n",
      "Logistic Regression Evaluation on SMOTE Balanced Test Set:\n",
      "Accuracy: 0.9842\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1172\n",
      "           1       1.00      0.97      0.98      1172\n",
      "\n",
      "    accuracy                           0.98      2344\n",
      "   macro avg       0.98      0.98      0.98      2344\n",
      "weighted avg       0.98      0.98      0.98      2344\n",
      "\n",
      "\n",
      "Random Forest Evaluation on SMOTE Balanced Test Set:\n",
      "Accuracy: 0.9991\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1172\n",
      "           1       1.00      1.00      1.00      1172\n",
      "\n",
      "    accuracy                           1.00      2344\n",
      "   macro avg       1.00      1.00      1.00      2344\n",
      "weighted avg       1.00      1.00      1.00      2344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Classification after balancing the dataset using SMOTE\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "file_path = r\"C:\\Users\\imran\\Downloads\\data.csv\"  # Update the file path\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Step 2: Filter Data for UK Customers\n",
    "data_uk = data[data['Country'] == 'United Kingdom']\n",
    "\n",
    "# Step 3: Data Cleaning and Feature Engineering\n",
    "data_cleaned = data_uk.dropna(subset=['CustomerID']).copy()\n",
    "data_cleaned['InvoiceDate'] = pd.to_datetime(data_cleaned['InvoiceDate'])\n",
    "data_cleaned['TotalAmount'] = data_cleaned['Quantity'] * data_cleaned['UnitPrice']\n",
    "data_cleaned['Recency'] = (data_cleaned['InvoiceDate'].max() - data_cleaned['InvoiceDate']).dt.days\n",
    "\n",
    "# Aggregate features at the customer level\n",
    "customer_features = data_cleaned.groupby('CustomerID').agg(\n",
    "    TotalAmount=('TotalAmount', 'sum'),\n",
    "    TotalQuantity=('Quantity', 'sum'),\n",
    "    AvgUnitPrice=('UnitPrice', 'mean'),\n",
    "    Recency=('Recency', 'min'),\n",
    "    Frequency=('InvoiceNo', 'nunique'),\n",
    "    Purchase=('TotalAmount', lambda x: 1 if x.sum() > 0 else 0)  # Target: Purchase (1/0)\n",
    ").reset_index()\n",
    "\n",
    "# Replace zeros or negative values in TotalQuantity and TotalAmount\n",
    "customer_features['TotalQuantity'] = customer_features['TotalQuantity'].replace(0, 1e-6)\n",
    "customer_features['TotalAmount'] = customer_features['TotalAmount'].replace(0, 1e-6)\n",
    "\n",
    "# Log-transform skewed features to reduce outliers\n",
    "customer_features['Log_TotalQuantity'] = np.log1p(customer_features['TotalQuantity'])\n",
    "customer_features['Log_TotalAmount'] = np.log1p(customer_features['TotalAmount'])\n",
    "\n",
    "# Replace infinite and NaN values\n",
    "customer_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "customer_features.dropna(inplace=True)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = ['TotalQuantity', 'AvgUnitPrice', 'Recency', 'Frequency', 'Log_TotalQuantity']\n",
    "customer_features[numeric_columns] = scaler.fit_transform(customer_features[numeric_columns])\n",
    "\n",
    "# Step 4: Define Features (X) and Target (y)\n",
    "X = customer_features.drop(columns=['CustomerID', 'Purchase', 'TotalAmount', 'Log_TotalAmount'])\n",
    "y = customer_features['Purchase']\n",
    "\n",
    "# Check class distribution\n",
    "print(\"UK dataset class distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Step 5: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Step 6: Balance Training Data with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nTraining set class distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_smote).value_counts())\n",
    "\n",
    "# Step 7: Adjust SMOTE for Test Data Based on Minority Class Size\n",
    "minority_class_samples = sum(y_test == 0)\n",
    "adjusted_neighbors = max(1, minority_class_samples - 1)  # Ensure valid k_neighbors\n",
    "smote_test = SMOTE(random_state=42, k_neighbors=adjusted_neighbors)\n",
    "X_test_smote, y_test_smote = smote_test.fit_resample(X_test, y_test)\n",
    "\n",
    "print(\"\\nTesting set class distribution after SMOTE:\")\n",
    "print(pd.Series(y_test_smote).value_counts())\n",
    "\n",
    "# Step 8: Train Logistic Regression with Class Weights\n",
    "log_reg = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "log_reg.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Step 9: Train Random Forest with Class Weights\n",
    "rf_clf = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100, max_depth=8)\n",
    "rf_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Step 10: Evaluate Logistic Regression on Balanced Test Set\n",
    "print(\"\\nLogistic Regression Evaluation on SMOTE Balanced Test Set:\")\n",
    "y_pred_log_reg_bal = log_reg.predict(X_test_smote)\n",
    "print(f\"Accuracy: {accuracy_score(y_test_smote, y_pred_log_reg_bal):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_smote, y_pred_log_reg_bal))\n",
    "\n",
    "# Step 11: Evaluate Random Forest on Balanced Test Set\n",
    "print(\"\\nRandom Forest Evaluation on SMOTE Balanced Test Set:\")\n",
    "y_pred_rf_bal = rf_clf.predict(X_test_smote)\n",
    "print(f\"Accuracy: {accuracy_score(y_test_smote, y_pred_rf_bal):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_smote, y_pred_rf_bal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95271b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in the dataset: 541909\n",
      "Number of records from the UK: 495478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1846: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])  # type: ignore[arg-type]\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:364: RuntimeWarning: divide by zero encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:364: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1846: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])  # type: ignore[arg-type]\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1846: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])  # type: ignore[arg-type]\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1846: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])  # type: ignore[arg-type]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression Models:\n",
      "\n",
      "Linear Regression Results:\n",
      "Mean Squared Error (MSE): 23626797.80\n",
      "R-squared (R²): 0.6594\n",
      "\n",
      "Linear Regression: Predicted vs Actual Revenue (Sample)\n",
      "       Actual    Predicted\n",
      "2965   391.52   291.686059\n",
      "1981   348.60   321.856981\n",
      "2450   681.19   483.296559\n",
      "1444  2456.80  1868.891403\n",
      "2727   140.70   205.964574\n",
      "2856   380.39   186.143384\n",
      "198   1708.86  2697.128431\n",
      "2364   108.38   279.302189\n",
      "2672   480.92   560.488632\n",
      "1459   841.20  1155.266095\n",
      "\n",
      "Decision Tree Results:\n",
      "Mean Squared Error (MSE): 25822631.86\n",
      "R-squared (R²): 0.6277\n",
      "\n",
      "Decision Tree: Predicted vs Actual Revenue (Sample)\n",
      "       Actual    Predicted\n",
      "2965   391.52   321.138171\n",
      "1981   348.60   433.881723\n",
      "2450   681.19   683.754821\n",
      "1444  2456.80  2555.309130\n",
      "2727   140.70   147.729657\n",
      "2856   380.39   253.229000\n",
      "198   1708.86  1510.048333\n",
      "2364   108.38   147.729657\n",
      "2672   480.92   511.301384\n",
      "1459   841.20   905.266460\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable Statistics (TotalAmount):\n",
      "count    3.912000e+03\n",
      "mean     1.733062e+03\n",
      "std      6.576868e+03\n",
      "min     -5.329071e-15\n",
      "25%      2.907150e+02\n",
      "50%      6.352550e+02\n",
      "75%      1.534990e+03\n",
      "max      2.564385e+05\n",
      "Name: TotalAmount, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:100: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  result = nanpercentile(\n"
     ]
    }
   ],
   "source": [
    "#regression for original dataset.\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "file_path = r\"C:\\Users\\imran\\Downloads\\data.csv\"  # Update the file path\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Step 2: Filter Data for UK Customers\n",
    "data_uk = data[data['Country'] == 'United Kingdom']\n",
    "print(f\"Total records in the dataset: {data.shape[0]}\")\n",
    "print(f\"Number of records from the UK: {data_uk.shape[0]}\")\n",
    "\n",
    "# Step 3: Data Cleaning and Feature Engineering\n",
    "data_cleaned = data_uk.dropna(subset=['CustomerID']).copy()\n",
    "data_cleaned['InvoiceDate'] = pd.to_datetime(data_cleaned['InvoiceDate'])\n",
    "data_cleaned['TotalAmount'] = data_cleaned['Quantity'] * data_cleaned['UnitPrice']\n",
    "data_cleaned['Recency'] = (data_cleaned['InvoiceDate'].max() - data_cleaned['InvoiceDate']).dt.days\n",
    "\n",
    "# Aggregate features at the customer level\n",
    "customer_features = data_cleaned.groupby('CustomerID').agg(\n",
    "    TotalAmount=('TotalAmount', 'sum'),\n",
    "    TotalQuantity=('Quantity', 'sum'),\n",
    "    AvgUnitPrice=('UnitPrice', 'mean'),\n",
    "    Recency=('Recency', 'min'),\n",
    "    Frequency=('InvoiceNo', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# Replace zeros or negative values in TotalQuantity\n",
    "customer_features['TotalQuantity'] = customer_features['TotalQuantity'].replace(0, 1e-6)\n",
    "\n",
    "# Log-transform skewed features to reduce outliers\n",
    "customer_features['Log_TotalQuantity'] = np.log1p(customer_features['TotalQuantity'])\n",
    "customer_features['Log_TotalAmount'] = np.log1p(customer_features['TotalAmount'])\n",
    "\n",
    "# Replace infinite and NaN values\n",
    "customer_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "customer_features.dropna(inplace=True)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = ['TotalQuantity', 'AvgUnitPrice', 'Recency', 'Frequency', 'Log_TotalQuantity']\n",
    "customer_features[numeric_columns] = scaler.fit_transform(customer_features[numeric_columns])\n",
    "\n",
    "# Step 4: Define Features (X) and Target (y)\n",
    "X = customer_features.drop(columns=['CustomerID', 'TotalAmount', 'Log_TotalAmount'])\n",
    "y = customer_features['TotalAmount']  # Predicting Total Revenue (continuous target)\n",
    "\n",
    "# Step 5: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 6: Regression Models\n",
    "print(\"\\nRegression Models:\")\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"\\nLinear Regression Results:\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred_lr):.2f}\")\n",
    "print(f\"R-squared (R²): {r2_score(y_test, y_pred_lr):.4f}\")\n",
    "\n",
    "# Display some predicted vs actual values\n",
    "print(\"\\nLinear Regression: Predicted vs Actual Revenue (Sample)\")\n",
    "predicted_vs_actual_lr = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_lr})\n",
    "print(predicted_vs_actual_lr.head(10))  # Show first 10 rows\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor(random_state=42, max_depth=8)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print(\"\\nDecision Tree Results:\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred_dt):.2f}\")\n",
    "print(f\"R-squared (R²): {r2_score(y_test, y_pred_dt):.4f}\")\n",
    "\n",
    "# Display some predicted vs actual values\n",
    "print(\"\\nDecision Tree: Predicted vs Actual Revenue (Sample)\")\n",
    "predicted_vs_actual_dt = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_dt})\n",
    "print(predicted_vs_actual_dt.head(10))  # Show first 10 rows\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize the distribution of the target variable (TotalAmount)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(customer_features['TotalAmount'], kde=True, bins=30, color='blue')\n",
    "plt.title(\"Distribution of Total Amount (Target Variable)\")\n",
    "plt.xlabel(\"TotalAmount\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Check basic statistics\n",
    "print(\"Target Variable Statistics (TotalAmount):\")\n",
    "print(customer_features['TotalAmount'].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0139e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in the dataset: 541909\n",
      "Number of records from the UK: 495478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1846: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])  # type: ignore[arg-type]\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:364: RuntimeWarning: divide by zero encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:364: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1846: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])  # type: ignore[arg-type]\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1846: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])  # type: ignore[arg-type]\n",
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1846: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])  # type: ignore[arg-type]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression Models:\n",
      "\n",
      "Linear Regression Results:\n",
      "Mean Squared Error (MSE): 0.3400\n",
      "R-squared (R²): 0.7963\n",
      "\n",
      "Linear Regression: Predicted vs Actual Revenue (Sample)\n",
      "        Actual  Predicted\n",
      "2965  5.972587   6.020212\n",
      "1981  5.856790   5.563573\n",
      "2450  6.525308   6.138837\n",
      "1444  7.807022   7.448620\n",
      "2727  4.953712   5.097694\n",
      "2856  5.943822   5.217813\n",
      "198   7.444167   7.818937\n",
      "2364  4.694828   5.168811\n",
      "2672  6.177778   6.364837\n",
      "1459  6.736018   7.037064\n",
      "\n",
      "Decision Tree Results:\n",
      "Mean Squared Error (MSE): 0.2239\n",
      "R-squared (R²): 0.8659\n",
      "\n",
      "Decision Tree: Predicted vs Actual Revenue (Sample)\n",
      "        Actual  Predicted\n",
      "2965  5.972587   5.978899\n",
      "1981  5.856790   5.744190\n",
      "2450  6.525308   6.395194\n",
      "1444  7.807022   7.745259\n",
      "2727  4.953712   4.772478\n",
      "2856  5.943822   5.537600\n",
      "198   7.444167   6.894070\n",
      "2364  4.694828   4.587171\n",
      "2672  6.177778   6.280916\n",
      "1459  6.736018   6.904008\n",
      "\n",
      "Gradient Boosting Regressor Results:\n",
      "Mean Squared Error (MSE): 0.1793\n",
      "R-squared (R²): 0.8926\n",
      "\n",
      "Gradient Boosting Regressor: Predicted vs Actual Revenue (Sample)\n",
      "        Actual  Predicted\n",
      "2965  5.972587   6.021960\n",
      "1981  5.856790   5.680064\n",
      "2450  6.525308   6.395256\n",
      "1444  7.807022   7.693583\n",
      "2727  4.953712   4.816360\n",
      "2856  5.943822   5.596791\n",
      "198   7.444167   7.279623\n",
      "2364  4.694828   4.516174\n",
      "2672  6.177778   6.375845\n",
      "1459  6.736018   6.901194\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable Statistics:\n",
      "count    3.912000e+03\n",
      "mean     6.510161e+00\n",
      "std      1.271735e+00\n",
      "min     -5.329071e-15\n",
      "25%      5.675777e+00\n",
      "50%      6.455599e+00\n",
      "75%      7.336930e+00\n",
      "max      1.245465e+01\n",
      "Name: Log_TotalAmount, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:100: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  result = nanpercentile(\n"
     ]
    }
   ],
   "source": [
    "#log transformation for the target variable\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "file_path = r\"C:\\Users\\imran\\Downloads\\data.csv\"  # Update the file path\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Step 2: Filter Data for UK Customers\n",
    "data_uk = data[data['Country'] == 'United Kingdom']\n",
    "print(f\"Total records in the dataset: {data.shape[0]}\")\n",
    "print(f\"Number of records from the UK: {data_uk.shape[0]}\")\n",
    "\n",
    "# Step 3: Data Cleaning and Feature Engineering\n",
    "data_cleaned = data_uk.dropna(subset=['CustomerID']).copy()\n",
    "data_cleaned['InvoiceDate'] = pd.to_datetime(data_cleaned['InvoiceDate'])\n",
    "data_cleaned['TotalAmount'] = data_cleaned['Quantity'] * data_cleaned['UnitPrice']\n",
    "data_cleaned['Recency'] = (data_cleaned['InvoiceDate'].max() - data_cleaned['InvoiceDate']).dt.days\n",
    "\n",
    "# Aggregate features at the customer level\n",
    "customer_features = data_cleaned.groupby('CustomerID').agg(\n",
    "    TotalAmount=('TotalAmount', 'sum'),\n",
    "    TotalQuantity=('Quantity', 'sum'),\n",
    "    AvgUnitPrice=('UnitPrice', 'mean'),\n",
    "    Recency=('Recency', 'min'),\n",
    "    Frequency=('InvoiceNo', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# Replace zeros or negative values in TotalQuantity\n",
    "customer_features['TotalQuantity'] = customer_features['TotalQuantity'].replace(0, 1e-6)\n",
    "\n",
    "# Log-transform skewed features and target variable\n",
    "customer_features['Log_TotalQuantity'] = np.log1p(customer_features['TotalQuantity'])\n",
    "customer_features['Log_TotalAmount'] = np.log1p(customer_features['TotalAmount'])\n",
    "\n",
    "# Replace infinite and NaN values\n",
    "customer_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "customer_features.dropna(inplace=True)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = ['TotalQuantity', 'AvgUnitPrice', 'Recency', 'Frequency', 'Log_TotalQuantity']\n",
    "customer_features[numeric_columns] = scaler.fit_transform(customer_features[numeric_columns])\n",
    "\n",
    "# Step 4: Define Features (X) and Target (y)\n",
    "X = customer_features.drop(columns=['CustomerID', 'TotalAmount', 'Log_TotalAmount'])\n",
    "y = customer_features['Log_TotalAmount']  # Predicting log-transformed revenue\n",
    "\n",
    "# Step 5: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 6: Train and Evaluate Models\n",
    "print(\"\\nRegression Models:\")\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"\\nLinear Regression Results:\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"R-squared (R²): {r2_score(y_test, y_pred_lr):.4f}\")\n",
    "\n",
    "# Display predicted vs actual values for Linear Regression\n",
    "print(\"\\nLinear Regression: Predicted vs Actual Revenue (Sample)\")\n",
    "predicted_vs_actual_lr = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_lr})\n",
    "print(predicted_vs_actual_lr.head(10))  # Show first 10 rows\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor(random_state=42, max_depth=8)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print(\"\\nDecision Tree Results:\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred_dt):.4f}\")\n",
    "print(f\"R-squared (R²): {r2_score(y_test, y_pred_dt):.4f}\")\n",
    "\n",
    "# Display predicted vs actual values for Decision Tree Regressor\n",
    "print(\"\\nDecision Tree: Predicted vs Actual Revenue (Sample)\")\n",
    "predicted_vs_actual_dt = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_dt})\n",
    "print(predicted_vs_actual_dt.head(10))  # Show first 10 rows\n",
    "\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(random_state=42, n_estimators=200, learning_rate=0.1, max_depth=5)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred_gbr = gbr.predict(X_test)\n",
    "print(\"\\nGradient Boosting Regressor Results:\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred_gbr):.4f}\")\n",
    "print(f\"R-squared (R²): {r2_score(y_test, y_pred_gbr):.4f}\")\n",
    "# Display predicted vs actual values for Gradient Boosting Regressor\n",
    "print(\"\\nGradient Boosting Regressor: Predicted vs Actual Revenue (Sample)\")\n",
    "predicted_vs_actual_gbr = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_gbr})\n",
    "print(predicted_vs_actual_gbr.head(10))  # Show first 10 rows\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize the distribution of the target variable\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(customer_features['Log_TotalAmount'], kde=True, bins=30)\n",
    "plt.title(\"Distribution of Log-Transformed Total Amount (Target Variable)\")\n",
    "plt.xlabel(\"Log_TotalAmount\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Check basic statistics\n",
    "print(\"Target Variable Statistics:\")\n",
    "print(customer_features['Log_TotalAmount'].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad8f4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Evaluation:\n",
      "Accuracy: 0.9975\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       952\n",
      "           1       1.00      0.99      0.99       233\n",
      "\n",
      "    accuracy                           1.00      1185\n",
      "   macro avg       1.00      0.99      1.00      1185\n",
      "weighted avg       1.00      1.00      1.00      1185\n",
      "\n",
      "\n",
      "Random Forest Evaluation:\n",
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       952\n",
      "           1       1.00      1.00      1.00       233\n",
      "\n",
      "    accuracy                           1.00      1185\n",
      "   macro avg       1.00      1.00      1.00      1185\n",
      "weighted avg       1.00      1.00      1.00      1185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#churn prediction\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "file_path = r\"C:\\Users\\imran\\Downloads\\data.csv\"  # Update the file path\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Step 2: Filter Data for UK Customers\n",
    "data_uk = data[data['Country'] == 'United Kingdom']\n",
    "\n",
    "# Step 3: Data Cleaning and Feature Engineering\n",
    "data_cleaned = data_uk.dropna(subset=['CustomerID']).copy()\n",
    "data_cleaned['InvoiceDate'] = pd.to_datetime(data_cleaned['InvoiceDate'])\n",
    "data_cleaned['TotalAmount'] = data_cleaned['Quantity'] * data_cleaned['UnitPrice']\n",
    "\n",
    "# Create Recency feature (days since last purchase)\n",
    "latest_date = data_cleaned['InvoiceDate'].max()\n",
    "data_cleaned['Recency'] = (latest_date - data_cleaned['InvoiceDate']).dt.days\n",
    "\n",
    "# Aggregate features at the customer level\n",
    "customer_features = data_cleaned.groupby('CustomerID').agg(\n",
    "    TotalAmount=('TotalAmount', 'sum'),\n",
    "    TotalQuantity=('Quantity', 'sum'),\n",
    "    AvgUnitPrice=('UnitPrice', 'mean'),\n",
    "    Recency=('Recency', 'min'),\n",
    "    Frequency=('InvoiceNo', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# Define Churn (target variable) as Recency > 180 days (example)\n",
    "customer_features['Churn'] = np.where(customer_features['Recency'] > 180, 1, 0)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = ['TotalQuantity', 'AvgUnitPrice', 'Recency', 'Frequency']\n",
    "customer_features[numeric_columns] = scaler.fit_transform(customer_features[numeric_columns])\n",
    "\n",
    "# Step 4: Define Features (X) and Target (y)\n",
    "X = customer_features.drop(columns=['CustomerID', 'Churn', 'TotalAmount'])\n",
    "y = customer_features['Churn']\n",
    "\n",
    "# Step 5: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Step 6: Train Models\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Evaluate Models\n",
    "# Logistic Regression Results\n",
    "print(\"Logistic Regression Evaluation:\")\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log_reg):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "\n",
    "# Random Forest Results\n",
    "print(\"\\nRandom Forest Evaluation:\")\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0248e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\imran\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - mlxtend\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.14.0               |   py39hcbf5309_0         1.0 MB  conda-forge\n",
      "    mlxtend-0.23.3             |     pyhd8ed1ab_0         1.2 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  mlxtend            conda-forge/noarch::mlxtend-0.23.3-pyhd8ed1ab_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               4.12.0-py39hcbf5309_0 --> 4.14.0-py39hcbf5309_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "mlxtend-0.23.3       | 1.2 MB    |            |   0% \n",
      "mlxtend-0.23.3       | 1.2 MB    | 1          |   1% \n",
      "mlxtend-0.23.3       | 1.2 MB    | ########## | 100% \n",
      "mlxtend-0.23.3       | 1.2 MB    | ########## | 100% \n",
      "\n",
      "conda-4.14.0         | 1.0 MB    |            |   0% \n",
      "conda-4.14.0         | 1.0 MB    | #######3   |  74% \n",
      "conda-4.14.0         | 1.0 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge mlxtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24733cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.3\n"
     ]
    }
   ],
   "source": [
    "import mlxtend\n",
    "print(mlxtend.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a726330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "       support        itemsets\n",
      "0     0.112264        (85123A)\n",
      "1     0.023901        (84029G)\n",
      "2     0.021931        (84029E)\n",
      "3     0.018099         (22752)\n",
      "4     0.017087         (71053)\n",
      "...        ...             ...\n",
      "2072  0.012137  (23355, 23356)\n",
      "2073  0.014053  (22112, 23355)\n",
      "2074  0.010114  (22633, 23439)\n",
      "2075  0.011445  (23439, 22865)\n",
      "2076  0.010380  (22866, 23439)\n",
      "\n",
      "[2077 rows x 2 columns]\n",
      "\n",
      "Association Rules:\n",
      "         antecedents consequents  antecedent support  consequent support  \\\n",
      "0            (22632)     (22865)            0.020068            0.033536   \n",
      "1            (22632)     (22866)            0.020068            0.028745   \n",
      "2            (22748)     (22745)            0.019962            0.019376   \n",
      "3            (22745)     (22748)            0.019376            0.019962   \n",
      "4     (22961, 22720)     (22960)            0.016715            0.053178   \n",
      "...              ...         ...                 ...                 ...   \n",
      "1144         (23295)     (23294)            0.020441            0.016182   \n",
      "1145         (23319)     (22086)            0.019216            0.059885   \n",
      "1146         (23356)     (23355)            0.024220            0.040190   \n",
      "1147         (23439)     (22865)            0.020547            0.033536   \n",
      "1148         (23439)     (22866)            0.020547            0.028745   \n",
      "\n",
      "       support  confidence       lift  representativity  leverage  conviction  \\\n",
      "0     0.010859    0.541114  16.135506               1.0  0.010186    2.106110   \n",
      "1     0.010593    0.527851  18.363366               1.0  0.010016    2.057097   \n",
      "2     0.014106    0.706667  36.470989               1.0  0.013719    3.343036   \n",
      "3     0.014106    0.728022  36.470989               1.0  0.013719    3.603373   \n",
      "4     0.010061    0.601911  11.318816               1.0  0.009172    2.378417   \n",
      "...        ...         ...        ...               ...       ...         ...   \n",
      "1144  0.010753    0.526042  32.507299               1.0  0.010422    2.075747   \n",
      "1145  0.010114    0.526316   8.788772               1.0  0.008963    1.984687   \n",
      "1146  0.012137    0.501099  12.468403               1.0  0.011163    1.923849   \n",
      "1147  0.011445    0.556995  16.609055               1.0  0.010756    2.181610   \n",
      "1148  0.010380    0.505181  17.574698               1.0  0.009789    1.962851   \n",
      "\n",
      "      zhangs_metric   jaccard  certainty  kulczynski  \n",
      "0          0.957235  0.254047   0.525191    0.432462  \n",
      "1          0.964908  0.277159   0.513878    0.448185  \n",
      "2          0.992391  0.559072   0.700871    0.717344  \n",
      "3          0.991798  0.559072   0.722482    0.717344  \n",
      "4          0.927148  0.168149   0.579552    0.395550  \n",
      "...             ...       ...        ...         ...  \n",
      "1144       0.989463  0.415638   0.518246    0.595258  \n",
      "1145       0.903582  0.146605   0.496142    0.347602  \n",
      "1146       0.942628  0.232179   0.480209    0.401543  \n",
      "1147       0.959507  0.268414   0.541623    0.449132  \n",
      "1148       0.962885  0.266758   0.490537    0.433146  \n",
      "\n",
      "[1149 rows x 14 columns]\n",
      "           antecedents consequents  antecedent support  consequent support  \\\n",
      "2              (22748)     (22745)            0.019962            0.019376   \n",
      "3              (22745)     (22748)            0.019376            0.019962   \n",
      "4       (22961, 22720)     (22960)            0.016715            0.053178   \n",
      "7     (82494L, 85123A)     (82482)            0.016395            0.057277   \n",
      "10             (21733)    (85123A)            0.037475            0.112264   \n",
      "...                ...         ...                 ...                 ...   \n",
      "1138           (23295)     (23293)            0.020441            0.025125   \n",
      "1139           (23296)     (23293)            0.017140            0.025125   \n",
      "1140           (23296)     (23295)            0.017140            0.020441   \n",
      "1142           (23294)     (23293)            0.016182            0.025125   \n",
      "1143           (23294)     (23295)            0.016182            0.020441   \n",
      "\n",
      "       support  confidence       lift  representativity  leverage  conviction  \\\n",
      "2     0.014106    0.706667  36.470989               1.0  0.013719    3.343036   \n",
      "3     0.014106    0.728022  36.470989               1.0  0.013719    3.603373   \n",
      "4     0.010061    0.601911  11.318816               1.0  0.009172    2.378417   \n",
      "7     0.010487    0.639610  11.167027               1.0  0.009547    2.615845   \n",
      "10    0.024593    0.656250   5.845573               1.0  0.020386    2.582503   \n",
      "...        ...         ...        ...               ...       ...         ...   \n",
      "1138  0.013893    0.679688  27.052139               1.0  0.013380    3.043512   \n",
      "1139  0.011551    0.673913  26.822310               1.0  0.011121    2.989616   \n",
      "1140  0.010327    0.602484  29.474670               1.0  0.009976    2.464204   \n",
      "1142  0.011551    0.713816  28.410473               1.0  0.011145    3.406459   \n",
      "1143  0.010753    0.664474  32.507299               1.0  0.010422    2.919471   \n",
      "\n",
      "      zhangs_metric   jaccard  certainty  kulczynski  \n",
      "2          0.992391  0.559072   0.700871    0.717344  \n",
      "3          0.991798  0.559072   0.722482    0.717344  \n",
      "4          0.927148  0.168149   0.579552    0.395550  \n",
      "7          0.925626  0.165965   0.617714    0.411348  \n",
      "10         0.861204  0.196512   0.612779    0.437656  \n",
      "...             ...       ...        ...         ...  \n",
      "1138       0.983130  0.438655   0.671432    0.616327  \n",
      "1139       0.979507  0.376083   0.665509    0.566829  \n",
      "1140       0.982920  0.378906   0.594189    0.553846  \n",
      "1142       0.980671  0.388193   0.706440    0.586781  \n",
      "1143       0.985180  0.415638   0.657472    0.595258  \n",
      "\n",
      "[724 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "file_path = r\"C:\\Users\\imran\\Downloads\\data.csv\"  # Update the file path\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Step 2: Filter Data for UK Customers\n",
    "data_uk = data[data['Country'] == 'United Kingdom']\n",
    "\n",
    "# Step 3: Data Cleaning for Association Mining\n",
    "# Retain relevant columns (InvoiceNo, StockCode, Quantity)\n",
    "data_cleaned = data_uk[['InvoiceNo', 'StockCode', 'Quantity']].copy()\n",
    "data_cleaned = data_cleaned[data_cleaned['Quantity'] > 0]  # Remove negative quantities\n",
    "\n",
    "# Create a basket-like structure (transactions by InvoiceNo)\n",
    "basket = data_cleaned.groupby(['InvoiceNo', 'StockCode'])['Quantity'].sum().unstack().reset_index().fillna(0)\n",
    "basket.set_index('InvoiceNo', inplace=True)\n",
    "\n",
    "# Convert quantities to 1/0 (presence/absence of items)\n",
    "basket = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Step 4: Perform FP-Growth Algorithm\n",
    "frequent_itemsets = fpgrowth(basket, min_support=0.01, use_colnames=True)\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Step 5: Generate Association Rules with num_itemsets\n",
    "num_itemsets = len(frequent_itemsets)  # Calculate the number of itemsets\n",
    "rules = association_rules(frequent_itemsets,num_itemsets=num_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)\n",
    "filtered_rules = rules[(rules['confidence'] > 0.6) & (rules['lift'] > 1.5)]\n",
    "print(filtered_rules)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c267532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imran\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "      support         itemsets\n",
      "0    0.112264         (85123A)\n",
      "1    0.023901         (84029G)\n",
      "2    0.021931         (84029E)\n",
      "3    0.025338          (22633)\n",
      "4    0.020068          (22632)\n",
      "..        ...              ...\n",
      "366  0.025924   (23203, 23202)\n",
      "367  0.028692  (23203, 85099B)\n",
      "368  0.024114   (23203, 23209)\n",
      "369  0.022464   (23209, 20725)\n",
      "370  0.028798   (23301, 23300)\n",
      "\n",
      "[371 rows x 2 columns]\n",
      "\n",
      "Filtered Association Rules:\n",
      "       antecedents     consequents  antecedent support  consequent support  \\\n",
      "25  (22699, 22697)         (22698)            0.037315            0.037421   \n",
      "28         (22698)  (22699, 22697)            0.037421            0.037315   \n",
      "26  (22699, 22698)         (22697)            0.029064            0.049718   \n",
      "27  (22697, 22698)         (22699)            0.030714            0.050942   \n",
      "23         (22698)         (22697)            0.037421            0.049718   \n",
      "24         (22698)         (22699)            0.037421            0.050942   \n",
      "30         (23300)         (23301)            0.039923            0.047802   \n",
      "20         (22356)         (20724)            0.035878            0.048174   \n",
      "13         (22699)         (22697)            0.050942            0.049718   \n",
      "14         (22697)         (22699)            0.049718            0.050942   \n",
      "\n",
      "     support  confidence       lift  representativity  leverage  conviction  \\\n",
      "25  0.026243    0.703281  18.793510               1.0  0.024847    3.244075   \n",
      "28  0.026243    0.701280  18.793510               1.0  0.024847    3.222703   \n",
      "26  0.026243    0.902930  18.161082               1.0  0.024798    9.789699   \n",
      "27  0.026243    0.854419  16.772333               1.0  0.024678    6.519123   \n",
      "23  0.030714    0.820768  16.508512               1.0  0.028854    5.301971   \n",
      "24  0.029064    0.776671  15.246133               1.0  0.027158    4.249603   \n",
      "30  0.028798    0.721333  15.090165               1.0  0.026890    3.416980   \n",
      "20  0.025498    0.710682  14.752355               1.0  0.023769    3.289901   \n",
      "13  0.037315    0.732497  14.733079               1.0  0.034782    3.552422   \n",
      "14  0.037315    0.750535  14.733079               1.0  0.034782    3.804378   \n",
      "\n",
      "    zhangs_metric   jaccard  certainty  kulczynski  \n",
      "25       0.983489  0.541164   0.691746    0.702281  \n",
      "28       0.983598  0.541164   0.689701    0.702281  \n",
      "26       0.973223  0.499493   0.897852    0.715384  \n",
      "27       0.970176  0.473583   0.846605    0.684785  \n",
      "23       0.975947  0.544340   0.811391    0.719271  \n",
      "24       0.970736  0.490126   0.764684    0.673602  \n",
      "30       0.972560  0.488708   0.707344    0.661892  \n",
      "20       0.966905  0.435455   0.696039    0.619982  \n",
      "13       0.982159  0.589076   0.718502    0.741516  \n",
      "14       0.980893  0.589076   0.737145    0.741516  \n",
      "\n",
      "Filtered Association Rules with Product Names:\n",
      "                                          antecedents  \\\n",
      "25  [ROSES REGENCY TEACUP AND SAUCER , GREEN REGEN...   \n",
      "28                                              [nan]   \n",
      "26            [ROSES REGENCY TEACUP AND SAUCER , nan]   \n",
      "27             [GREEN REGENCY TEACUP AND SAUCER, nan]   \n",
      "23                                              [nan]   \n",
      "24                                              [nan]   \n",
      "30               [GARDENERS KNEELING PAD CUP OF TEA ]   \n",
      "20                      [CHARLOTTE BAG PINK POLKADOT]   \n",
      "13                 [ROSES REGENCY TEACUP AND SAUCER ]   \n",
      "14                  [GREEN REGENCY TEACUP AND SAUCER]   \n",
      "\n",
      "                                          consequents  antecedent support  \\\n",
      "25                                              [nan]            0.037315   \n",
      "28  [ROSES REGENCY TEACUP AND SAUCER , GREEN REGEN...            0.037421   \n",
      "26                  [GREEN REGENCY TEACUP AND SAUCER]            0.029064   \n",
      "27                 [ROSES REGENCY TEACUP AND SAUCER ]            0.030714   \n",
      "23                  [GREEN REGENCY TEACUP AND SAUCER]            0.037421   \n",
      "24                 [ROSES REGENCY TEACUP AND SAUCER ]            0.037421   \n",
      "30                [GARDENERS KNEELING PAD KEEP CALM ]            0.039923   \n",
      "20                      [RED RETROSPOT CHARLOTTE BAG]            0.035878   \n",
      "13                  [GREEN REGENCY TEACUP AND SAUCER]            0.050942   \n",
      "14                 [ROSES REGENCY TEACUP AND SAUCER ]            0.049718   \n",
      "\n",
      "    consequent support   support  confidence       lift  representativity  \\\n",
      "25            0.037421  0.026243    0.703281  18.793510               1.0   \n",
      "28            0.037315  0.026243    0.701280  18.793510               1.0   \n",
      "26            0.049718  0.026243    0.902930  18.161082               1.0   \n",
      "27            0.050942  0.026243    0.854419  16.772333               1.0   \n",
      "23            0.049718  0.030714    0.820768  16.508512               1.0   \n",
      "24            0.050942  0.029064    0.776671  15.246133               1.0   \n",
      "30            0.047802  0.028798    0.721333  15.090165               1.0   \n",
      "20            0.048174  0.025498    0.710682  14.752355               1.0   \n",
      "13            0.049718  0.037315    0.732497  14.733079               1.0   \n",
      "14            0.050942  0.037315    0.750535  14.733079               1.0   \n",
      "\n",
      "    leverage  conviction  zhangs_metric   jaccard  certainty  kulczynski  \n",
      "25  0.024847    3.244075       0.983489  0.541164   0.691746    0.702281  \n",
      "28  0.024847    3.222703       0.983598  0.541164   0.689701    0.702281  \n",
      "26  0.024798    9.789699       0.973223  0.499493   0.897852    0.715384  \n",
      "27  0.024678    6.519123       0.970176  0.473583   0.846605    0.684785  \n",
      "23  0.028854    5.301971       0.975947  0.544340   0.811391    0.719271  \n",
      "24  0.027158    4.249603       0.970736  0.490126   0.764684    0.673602  \n",
      "30  0.026890    3.416980       0.972560  0.488708   0.707344    0.661892  \n",
      "20  0.023769    3.289901       0.966905  0.435455   0.696039    0.619982  \n",
      "13  0.034782    3.552422       0.982159  0.589076   0.718502    0.741516  \n",
      "14  0.034782    3.804378       0.980893  0.589076   0.737145    0.741516  \n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'association_rules.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12016/405502312.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# Save rules to a file for further analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mfiltered_rules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"association_rules.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3464\u001b[0m         )\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3466\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'association_rules.csv'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "file_path = r\"C:\\Users\\imran\\Downloads\\data.csv\"  # Update the file path\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Step 2: Filter Data for UK Customers\n",
    "data_uk = data[data['Country'] == 'United Kingdom']\n",
    "\n",
    "# Step 3: Data Cleaning for Association Mining\n",
    "# Retain relevant columns (InvoiceNo, StockCode, Quantity)\n",
    "data_cleaned = data_uk[['InvoiceNo', 'StockCode', 'Quantity']].copy()\n",
    "data_cleaned = data_cleaned[data_cleaned['Quantity'] > 0]  # Remove negative quantities\n",
    "\n",
    "# Create a basket-like structure (transactions by InvoiceNo)\n",
    "basket = data_cleaned.groupby(['InvoiceNo', 'StockCode'])['Quantity'].sum().unstack().reset_index().fillna(0)\n",
    "basket.set_index('InvoiceNo', inplace=True)\n",
    "\n",
    "# Convert quantities to 1/0 (presence/absence of items)\n",
    "basket = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Step 4: Perform FP-Growth Algorithm\n",
    "min_support = 0.02  # You can adjust this threshold\n",
    "frequent_itemsets = fpgrowth(basket, min_support=min_support, use_colnames=True)\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Step 5: Generate Association Rules\n",
    "num_itemsets = len(frequent_itemsets)  # Calculate the number of itemsets\n",
    "rules = association_rules(frequent_itemsets,num_itemsets=num_itemsets, metric=\"confidence\", min_threshold=0.6)\n",
    "\n",
    "# Filter rules for meaningful insights\n",
    "filtered_rules = rules[(rules['confidence'] > 0.7) & (rules['lift'] > 1.5)]\n",
    "filtered_rules = filtered_rules.sort_values(by=['lift', 'confidence'], ascending=False)\n",
    "\n",
    "# Display top association rules\n",
    "print(\"\\nFiltered Association Rules:\")\n",
    "print(filtered_rules.head(10))  # Show top 10 rules\n",
    "\n",
    "# Map StockCode to Product Names (if available)\n",
    "if 'Description' in data.columns:\n",
    "    product_map = data[['StockCode', 'Description']].drop_duplicates().set_index('StockCode')['Description'].to_dict()\n",
    "    filtered_rules['antecedents'] = filtered_rules['antecedents'].apply(lambda x: [product_map.get(item, item) for item in x])\n",
    "    filtered_rules['consequents'] = filtered_rules['consequents'].apply(lambda x: [product_map.get(item, item) for item in x])\n",
    "\n",
    "    print(\"\\nFiltered Association Rules with Product Names:\")\n",
    "    print(filtered_rules.head(10))\n",
    "\n",
    "# Save rules to a file for further analysis\n",
    "filtered_rules.to_csv(\"association_rules.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
